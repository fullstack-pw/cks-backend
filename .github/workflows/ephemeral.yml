name: PR Ephemeral Environment

on:
  pull_request:
    types: [opened, synchronize, reopened, closed]

env:
  REGISTRY: registry.fullstack.pw
  IMAGE_NAME: ${{ github.repository }}
  VAULT_ADDR: https://vault.fullstack.pw

jobs:
  manage-environment:
    runs-on: self-hosted
    steps:
      - name: Set cluster info
        id: cluster-info
        run: |
          CLUSTER_NAME="pr-${{ github.event.repository.name }}-${{ github.event.pull_request.number }}"
          DNS_NAME="pr-${{ github.event.pull_request.number }}-${{ github.event.repository.name }}.ephemeral.fullstack.pw"
          echo "cluster_name=$CLUSTER_NAME" >> $GITHUB_OUTPUT
          echo "dns_name=$DNS_NAME" >> $GITHUB_OUTPUT

      - name: Checkout infra repo
        uses: actions/checkout@v4
        with:
          repository: fullstack-pw/infra
          token: ${{ secrets.RUNNER }}
          path: infra

      - name: Check if cluster exists
        id: check-cluster
        run: |
          CLUSTER_NAME="${{ steps.cluster-info.outputs.cluster_name }}"
          if kubectl get cluster "$CLUSTER_NAME" -n "$CLUSTER_NAME" --context tools --kubeconfig /home/runner/.kube/config &>/dev/null; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "Cluster $CLUSTER_NAME already exists"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "Cluster $CLUSTER_NAME does not exist"
          fi

      # ==================== CREATE/UPDATE ENVIRONMENT ====================
      - name: Check IP pool capacity
        if: github.event.action != 'closed' && steps.check-cluster.outputs.exists == 'false'
        run: |
          cd infra
          AVAILABLE=$(./clusters/scripts/ip_pool_manager.sh check-capacity)
          CAPACITY_RESULT=$?
          echo "Capacity available: $AVAILABLE slots free"
          if [ "$CAPACITY_RESULT" -ne 0 ]; then
            echo "::error::IP pool exhausted. All 5 ephemeral cluster slots are in use (10 IPs / 2 per cluster). Please close old PRs."
            exit 1
          fi

      - name: Allocate IP from pool
        if: github.event.action != 'closed' && steps.check-cluster.outputs.exists == 'false'
        id: allocate
        run: |
          cd infra
          CLUSTER_NAME="${{ steps.cluster-info.outputs.cluster_name }}"
          CLUSTER_IP=$(./clusters/scripts/ip_pool_manager.sh allocate "$CLUSTER_NAME")

          # Calculate node IP (VIP + 1) - each cluster needs 2 IPs
          IP_LAST_OCTET=$(echo "$CLUSTER_IP" | cut -d'.' -f4)
          NODE_IP_LAST_OCTET=$((IP_LAST_OCTET + 1))
          NODE_IP="192.168.1.${NODE_IP_LAST_OCTET}"

          echo "ip=$CLUSTER_IP" >> $GITHUB_OUTPUT
          echo "node_ip=$NODE_IP" >> $GITHUB_OUTPUT
          echo "Allocated control plane VIP: $CLUSTER_IP"
          echo "Node IP: $NODE_IP"

      - name: Render Cluster API manifest
        if: github.event.action != 'closed' && steps.check-cluster.outputs.exists == 'false'
        run: |
          cd infra
          export CLUSTER_NAME="${{ steps.cluster-info.outputs.cluster_name }}"
          export CLUSTER_IP="${{ steps.allocate.outputs.ip }}"
          export NODE_IP="${{ steps.allocate.outputs.node_ip }}"
          export PR_NUMBER="${{ github.event.pull_request.number }}"
          export REPOSITORY="${{ github.event.repository.name }}"
          envsubst < ephemeral-clusters/cluster-api/k3s-cluster.yaml.tpl > /tmp/cluster.yaml
          cat /tmp/cluster.yaml

      - name: Create cluster via Cluster API
        if: github.event.action != 'closed' && steps.check-cluster.outputs.exists == 'false'
        run: |
          kubectl apply -f /tmp/cluster.yaml --context tools --kubeconfig /home/runner/.kube/config

      - name: Copy Proxmox credentials to namespace
        if: github.event.action != 'closed' && steps.check-cluster.outputs.exists == 'false'
        run: |
          CLUSTER_NAME="${{ steps.cluster-info.outputs.cluster_name }}"
          kubectl --context tools --kubeconfig /home/runner/.kube/config \
            get secret proxmox-credentials -n k3s-test -o json | \
            jq 'del(.metadata.namespace,.metadata.uid,.metadata.resourceVersion,.metadata.creationTimestamp,.metadata.ownerReferences,.metadata.finalizers)' | \
            kubectl --context tools --kubeconfig /home/runner/.kube/config apply -n "$CLUSTER_NAME" -f - || \
            echo "Warning: Could not copy proxmox-credentials (may already exist)"

      - name: Wait for cluster available
        if: github.event.action != 'closed' && steps.check-cluster.outputs.exists == 'false'
        run: |
          CLUSTER_NAME="${{ steps.cluster-info.outputs.cluster_name }}"
          echo "Waiting for cluster $CLUSTER_NAME to be available..."
          kubectl wait --for=condition=Available \
            cluster/$CLUSTER_NAME \
            -n $CLUSTER_NAME \
            --timeout=5m --context tools --kubeconfig /home/runner/.kube/config

      - name: Extract kubeconfig
        if: github.event.action != 'closed' && steps.check-cluster.outputs.exists == 'false'
        run: |
          CLUSTER_NAME="${{ steps.cluster-info.outputs.cluster_name }}"
          kubectl get secret ${CLUSTER_NAME}-kubeconfig \
            -n $CLUSTER_NAME \
            -o jsonpath='{.data.value}' --context tools --kubeconfig /home/runner/.kube/config | base64 -d > /tmp/kubeconfig

          # Rename context to match workspace name for OpenTofu
          ORIGINAL_CONTEXT=$(kubectl --kubeconfig /tmp/kubeconfig config current-context)
          kubectl --kubeconfig /tmp/kubeconfig config rename-context "$ORIGINAL_CONTEXT" "$CLUSTER_NAME"
          kubectl --kubeconfig /tmp/kubeconfig config use-context "$CLUSTER_NAME"

      - name: Apply ephemeral infrastructure with OpenTofu
        if: github.event.action != 'closed' && steps.check-cluster.outputs.exists == 'false'
        env:
          KUBECONFIG: /tmp/kubeconfig
        run: |
          cd infra
          make ephemeral-init
          make ephemeral-apply WORKSPACE=${{ steps.cluster-info.outputs.cluster_name }}

      # ==================== BUILD AND DEPLOY (PR opened/updated) ====================
      # - name: Checkout app code
      #   if: github.event.action != 'closed'
      #   uses: actions/checkout@v4

      # - name: Build and push Docker image
      #   if: github.event.action != 'closed'
      #   env:
      #     HARBOR_KEY: ${{ secrets.HARBOR_KEY }}
      #   run: |
      #     docker build -t ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:pr-${{ github.event.pull_request.number }} .
      #     echo "${HARBOR_KEY}" | docker login registry.fullstack.pw -u admin --password-stdin
      #     docker push ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:pr-${{ github.event.pull_request.number }}

      # - name: Get kubeconfig from Vault
      #   if: github.event.action != 'closed'
      #   env:
      #     VAULT_TOKEN: ${{ secrets.VAULT_TOKEN }}
      #   run: |
      #     vault kv get -field=PR_KUBECONFIG kv/cluster-secret-store/secrets > /tmp/pr-kubeconfig
      #     # Extract just this cluster's context
      #     export KUBECONFIG=/tmp/pr-kubeconfig
      #     kubectl config use-context ${{ steps.cluster-info.outputs.cluster_name }}

      # - name: Deploy to ephemeral cluster
      #   if: github.event.action != 'closed'
      #   run: |
      #     # Update image tag in kustomization
      #     cd kustomize/overlays/ephemeral
      #     kustomize edit set image registry.fullstack.pw/library/${{ github.event.repository.name }}=registry.fullstack.pw/library/${{ github.event.repository.name }}:pr-${{ github.event.pull_request.number }}
      #     cd ../../..

      #     # Apply kustomization
      #     kubectl apply -k kustomize/overlays/ephemeral --kubeconfig /tmp/pr-kubeconfig

      #     # Wait for deployment rollout
      #     kubectl rollout status deployment/${{ github.event.repository.name }} \
      #       -n default --timeout=5m --kubeconfig /tmp/pr-kubeconfig

      # - name: Run tests
      #   if: github.event.action != 'closed'
      #   run: |
      #     echo "Tests would run here against https://${{ steps.cluster-info.outputs.dns_name }}"
      #     # npx cypress run --config baseUrl=https://${{ steps.cluster-info.outputs.dns_name }}

      # - name: Post deployment info
      #   if: github.event.action != 'closed' && steps.check-cluster.outputs.exists == 'false'
      #   uses: actions/github-script@v7
      #   with:
      #     github-token: ${{ secrets.GITHUB_TOKEN }}
      #     script: |
      #       const dnsName = '${{ steps.cluster-info.outputs.dns_name }}';
      #       const clusterName = '${{ steps.cluster-info.outputs.cluster_name }}';

      #       const body = `## Ephemeral Environment Ready

      #       Your ephemeral environment has been deployed!

      #       **URL**: https://${dnsName}
      #       **Cluster**: \`${clusterName}\`

      #       The environment will be automatically destroyed when this PR is closed.
      #       `;

      #       github.rest.issues.createComment({
      #         owner: context.repo.owner,
      #         repo: context.repo.repo,
      #         issue_number: context.issue.number,
      #         body: body
      #       });

      # ==================== CLEANUP (PR closed) ====================
      - name: Get kubeconfig for destruction
        if: github.event.action == 'closed'
        run: |
          CLUSTER_NAME="${{ steps.cluster-info.outputs.cluster_name }}"
          kubectl get secret ${CLUSTER_NAME}-kubeconfig \
            -n $CLUSTER_NAME \
            -o jsonpath='{.data.value}' --context tools --kubeconfig /home/runner/.kube/config | base64 -d > /tmp/kubeconfig || true

          # Rename context to match workspace name for OpenTofu
          if [ -f /tmp/kubeconfig ]; then
            ORIGINAL_CONTEXT=$(kubectl --kubeconfig /tmp/kubeconfig config current-context 2>/dev/null || echo "")
            if [ -n "$ORIGINAL_CONTEXT" ]; then
              kubectl --kubeconfig /tmp/kubeconfig config rename-context "$ORIGINAL_CONTEXT" "$CLUSTER_NAME" 2>/dev/null || true
              kubectl --kubeconfig /tmp/kubeconfig config use-context "$CLUSTER_NAME" 2>/dev/null || true
            fi
          fi

      - name: Destroy ephemeral infrastructure with OpenTofu
        if: github.event.action == 'closed'
        env:
          KUBECONFIG: /tmp/kubeconfig
        run: |
          cd infra/ephemeral-clusters/opentofu
          tofu workspace select ${{ steps.cluster-info.outputs.cluster_name }} || true
          tofu destroy -auto-approve || true
          tofu workspace select default || true
          tofu workspace delete ${{ steps.cluster-info.outputs.cluster_name }} || true

      - name: Delete cluster
        if: github.event.action == 'closed'
        run: |
          CLUSTER_NAME="${{ steps.cluster-info.outputs.cluster_name }}"
          kubectl delete cluster $CLUSTER_NAME -n $CLUSTER_NAME --context tools --ignore-not-found=true --kubeconfig /home/runner/.kube/config

          # Wait for cluster deletion
          kubectl wait --for=delete cluster/$CLUSTER_NAME -n $CLUSTER_NAME \
            --timeout=5m --context tools --kubeconfig /home/runner/.kube/config || true

          # Delete namespace
          kubectl delete namespace $CLUSTER_NAME --context tools --ignore-not-found=true --kubeconfig /home/runner/.kube/config

      - name: Release IPs
        if: github.event.action == 'closed'
        run: |
          cd infra
          ./clusters/scripts/ip_pool_manager.sh release ${{ steps.cluster-info.outputs.cluster_name }}

      - name: Cleanup on failure
        if: failure() && github.event.action != 'closed'
        run: |
          cd infra
          CLUSTER_NAME="${{ steps.cluster-info.outputs.cluster_name }}"

          # Delete cluster if it was created
          kubectl delete cluster $CLUSTER_NAME -n $CLUSTER_NAME --context tools --ignore-not-found=true --kubeconfig /home/runner/.kube/config

          make ephemeral-destroy WORKSPACE=${{ steps.cluster-info.outputs.cluster_name }} || true

          # Release IP
          ./clusters/scripts/ip_pool_manager.sh release "$CLUSTER_NAME" || true
